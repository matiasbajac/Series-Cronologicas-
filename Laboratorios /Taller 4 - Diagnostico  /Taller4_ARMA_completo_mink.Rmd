---
title: "Taller 4 - ARMA completo"
subtitle: "Adaptado del taller 2022 de Federico Molina"
author: "Series Cronológicas 2024"
date: "Mayo 2024"
#bibliography: [bibliografia.bib]
output:
  pdf_document:
    #toc: true
    fig_caption: true
    keep_tex: yes
    number_sections: yes
    citation_package: natbib
    extra_dependencies:
      bbm: null
      amsthm: null
      amsmath: null
      babel: spanish
      float: 
  html_document:
    df_print: paged
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 50), fig.pos = 'H', out.extra = '',warning = FALSE,message = FALSE)

```

```{r, echo = FALSE}

# Cargamos las librerías
library(tidyverse)
library(here)
library(forecast)
library(gridExtra)
library(readxl)
library(lmtest)
library(TSA)
library(tsoutliers)
# library(xts)

```

# Análisis exploratorio

```{r, echo = FALSE}

# Cargamos los datos
mink <- fma::mink # ??mink
class(mink) # Objeto ts
str(mink) # Serie de tiempo entre 1848 y 1911
head(mink)
frequency(mink) # Datos anuales
length(mink) # 64 observaciones

```

```{r}

# Máximo valor observado y fecha en la que ocurrió
max(mink)
time(mink)[which.max(mink)]

# Mínimo valor observado y fecha en la que ocurrió
min(mink)
time(mink)[which.min(mink)]

```

```{r, fig.align = 'center', fig.cap = "Evolución de la cantidad anual de visones atrapados en el distrito río McKenzie al noroeste de Canadá entre 1848 y 1911.", fig.pos = 'H', warning = FALSE, message = FALSE}

# Graficamos la serie
autoplot(mink) +
  labs(x = "Año",
       y = "Visones atrapados") +
  theme(panel.grid.minor = element_blank())

```

# Identificación y estimación del modelo

```{r, fig.align = 'center', fig.cap = "Funciones de Autocorrelación y Autocorrelación Parcial estimadas de la cantidad de visones atrapados.", fig.pos = 'H'}

# FAC (no descartamos estacionariedad)
mink_acf <- ggAcf(mink, lag.max = 24, type = "correlation") +
  labs(x = "Rezago",
       y = "Autocorrelación",
       title = "")

# FACP
mink_pacf <- ggAcf(mink, lag.max = 24, type = "partial") +
  labs(x = "Rezago",
       y = "Autocorrelación parcial",
       title = "")

grid.arrange(mink_acf, mink_pacf)

```

```{r}

# Dada la forma de la FAC y la FACP, un posible modelo es un AR(1)

# AR(1)
modelo1 <- Arima(y = mink, # Datos para estimar
                 order = c(1, 0, 0), # Orden del modelo (suponemos estacionariedad)
                 lambda = NULL) # Trabajamos con la serie sin transformar

summary(modelo1)

```

```{r}

# Construimos "a mano" intervalos de confianza para los coeficientes del modelo
confint <- function(modelo, alfa = 0.05){
	coeficientes <- coef(modelo)
	desvio_estandar <- sqrt(diag(modelo$var.coef))
	l.inf <- coeficientes - qnorm(1 - alfa/2)*desvio_estandar
	l.sup <- coeficientes + qnorm(1 - alfa/2)*desvio_estandar
	IC <- cbind(l.inf, coeficientes, l.sup)
	colnames(IC) <- c(paste(round(alfa/2*100, 1),'%'), 'Estimación',
	                  paste(round((1 - alfa/2)*100, 1),'%'))
	IC <- as.data.frame(IC)
	return(round(IC, 3))
}

confint(modelo1)

# Otra forma
coefci(modelo1)

```

```{r}

# Testeamos "a mano" la significación de los coeficientes del modelo
# Utilizamos el test de Wald
significacion <- function(modelo){
	coeficientes <- coef(modelo)
	desvio_estandar <- sqrt(diag(modelo$var.coef))
	z <- coeficientes/desvio_estandar
	pv <- 2*(1 - pnorm(abs(z))) # Probabilidad de que z sea mayor que el z observado en valor absoluto
	significacion <- cbind(coeficientes, desvio_estandar, z, pv)
	colnames(significacion) <- c('Estimación','Desvío','z','P-valor')
	significacion <- as.data.frame(significacion)
	return(round(significacion, 3))
}

significacion(modelo1)

# Otra forma
coeftest(modelo1)

```

# Selección de modelos

## AIC

```{r}

# Armamos una matriz con los valores del AIC para valores del 1 al 6 de p y q

norder <- 6 # Máximo orden de rezagos que queremos considerar
aic <- matrix(0, norder + 1, norder + 1)
rownames(aic) <- c(0:norder)
colnames(aic) <- c(0:norder)

for (i in 1:(norder + 1)) {
  for (j in 1:(norder + 1)) {
    modeloij <- Arima(mink, order = c(i-1, 0, j-1), method = 'ML')
    aic[i,j] <- modeloij$aic
  }
}

aic
min(aic)
which(aic == min(aic), arr.ind = TRUE) # El AIC mínimo se da para un ARMA(2,3)

```

## AIC corregido

```{r}

# Armamos una matriz con los valores del AIC corregido para valores del 1 al 6 de p y q

norder <- 6 # Máximo orden de rezagos que queremos considerar
aicc <- matrix(0, norder + 1, norder + 1)
rownames(aicc) <- c(0:norder)
colnames(aicc) <- c(0:norder)

for (i in 1:(norder + 1)) {
  for (j in 1:(norder + 1)) {
    modeloij <- Arima(mink, order = c(i-1, 0, j-1), method = 'ML')
    aicc[i,j] <- modeloij$aicc
  }
}

aicc
min(aicc)
which(aicc == min(aicc), arr.ind = TRUE) # El AIC corregido mínimo se da para un ARMA(2,3)

```

## BIC

```{r}

# Armamos una matriz con los valores del BIC para valores del 1 al 6 de p y q

norder <- 6 # Máximo orden de rezagos que queremos considerar
bic <- matrix(0, norder + 1, norder + 1)
rownames(bic) <- c(0:norder)
colnames(bic) <- c(0:norder)

for (i in 1:(norder + 1)) {
  for (j in 1:(norder + 1)) {
    modeloij <- Arima(mink, order = c(i-1, 0, j-1), method = 'ML')
    bic[i,j] <- modeloij$bic
  }
}

bic
min(bic)
which(bic == min(bic), arr.ind = TRUE) # El BIC mínimo se da para un ARMA(2,3)

```

# Diagnóstico del modelo

## Análisis gráfico de los residuos

```{r}

# Guardamos los residuos del modelo
residuos1 <- modelo1$residuals

# Buscamos los residuos máximos y mínimos

max(residuos1)
which.max(residuos1)
time(residuos1)[which.max(residuos1)] # 1885

min(residuos1)
which.min(residuos1)
time(residuos1)[which.min(residuos1)] # 1870

```

```{r, fig.align = 'center', fig.cap = "Residuos de un modelo AR(1) para la cantidad de visones atrapados.", fig.pos = 'H'}

# Graficamos los residuos
residuos1 %>% autoplot() +
  labs(x = "Fecha",
      y = "Residuos") +
  geom_hline(yintercept = 0, color = "red")

```

## Autocorrelación de los residuos

### FAC y FACP de los residuos

```{r, fig.align = 'center', fig.cap = "Funciones de Autocorrelación y Autocorrelación Parcial estimadas de los residuos de un modelo ARMA(1,1) para la cantidad de visones atrapados.", fig.pos = 'H'}

# FAC
residuos_acf <- ggAcf(residuos1, lag.max = 24, type = "correlation") +
  labs(x = "Rezago",
       y = "Autocorrelación",
       title = "")

# FACP
residuos_pacf <- ggAcf(residuos1, lag.max = 24, type = "partial") +
  labs(x = "Rezago",
       y = "Autocorrelación parcial",
       title = "")

grid.arrange(residuos_acf, residuos_pacf)

# Otra posibilidad es graficar a la vez los residuos, su FAC y su FACP
# checkresiduals(residuos)
# tsdisplay(residuos)

```

### Contraste de autocorrelación de los residuos

```{r}

# Test de Ljung-Box
# Se rechaza la hipótsis nula de no autocorrelación de los residuos
Box.test(residuos1,
         lag = 40,
         type = "Ljung-Box",
         fitdf = 2) # p + q cuando testeamos la autocorrelación de residuos de un modelo ARMA(1,1)

```

# Segundo proceso de identificación y estimación del modelo

```{r}

# Teniendo en cuenta la forma de la FAC de los residuos,
# una opción es incluir un componente MA de orden 10

# ARMA(1,10)
modelo2 <- Arima(y = mink, # Datos para estimar
                order = c(1, 0, 10), # Orden del modelo (suponemos estacionariedad)
                fixed = c(NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA),
                lambda = NULL) # Trabajamos con la serie sin transformar

summary(modelo2)

```

```{r}

# Construimos "a mano" intervalos de confianza para los coeficientes del modelo
confint(modelo2) %>% 
  filter(`Estimación` != 0)

# Otra forma
coefci(modelo2)

```

```{r}

# Testeamos "a mano" la significación de los coeficientes del modelo
# Utilizamos el test de Wald
significacion(modelo2) %>% 
  filter(`Estimación` != 0)

# Otra forma
coeftest(modelo2)

```

```{r}

# Testeamos que el segundo modelo que estimamos sea mejor que el primero

# H0) AR(1)
# H1) ARMA(1,10)

# Usamos una prueba de razón de verosimilitud
L <- 2*(modelo2$loglik - modelo1$loglik)
# El p-valor se calcula como la probabilidad de que L sea mayor al observado bajo H0 cierta
1 - pchisq(L, 1) # Bajo H0, L se distribuye chi-cuadrado con un grado de libertad
# Se rechaza la hipótesis nula y se prefiere el segundo modelo al primero

```


```{r, fig.align = 'center', fig.cap = "Cantidad de visones atrapados y valores ajustados para un modelo ARMA(1,10).", fig.pos = 'H'}

# Graficamos la serie y los valores ajustados

ajuste <- data.frame(Fecha = seq(from = as.Date("1848-01-01"),
                                 to = as.Date("1911-01-01"), by = "year"),
                     Datos = mink,
                     Ajustados = modelo2$fitted) %>% 
  pivot_longer(cols = c(Datos, Ajustados),
               names_to = "Serie",
               values_to = "Valor") %>% 
  mutate(Serie = recode(Serie, Ajustados = "Valores ajustados"))

ggplot(ajuste) +
  geom_line(aes(x = Fecha, y = Valor, color = Serie)) +
  labs(title = "Modelo ARMA(1,10)")

```

# Segundo proceso de diagnóstico del modelo

## Análisis gráfico de los residuos

```{r}

# Guardamos los residuos del modelo
residuos2 <- modelo2$residuals

# Buscamos los residuos máximos y mínimos

max(residuos2)
which.max(residuos2)
time(residuos2)[which.max(residuos2)] # 1885

min(residuos2)
which.min(residuos2)
time(residuos2)[which.min(residuos2)] # 1870

```

```{r, fig.align = 'center', fig.cap = "Residuos de un modelo ARMA(1,10) para la cantidad de visones atrapados.", fig.pos = 'H'}

# Graficamos los residuos
residuos2 %>% autoplot() +
  labs(x = "Fecha",
      y = "Residuos") +
  geom_hline(yintercept = 0, color = "red")

```

## Autocorrelación de los residuos

### FAC y FACP de los residuos

```{r, fig.align = 'center', fig.cap = "Funciones de Autocorrelación y Autocorrelación Parcial estimadas de los residuos de un modelo ARMA(1,10) para la cantidad de visones atrapados.", fig.pos = 'H'}

# FAC
residuos_acf <- ggAcf(residuos2, lag.max = 24, type = "correlation") +
  labs(x = "Rezago",
       y = "Autocorrelación",
       title = "")

# FACP
residuos_pacf <- ggAcf(residuos2, lag.max = 24, type = "partial") +
  labs(x = "Rezago",
       y = "Autocorrelación parcial",
       title = "")

grid.arrange(residuos_acf, residuos_pacf)

# Otra posibilidad es graficar a la vez los residuos, su FAC y su FACP
# checkresiduals(residuos)
# tsdisplay(residuos)

```

### Contraste de autocorrelación de los residuos

```{r}

# Test de Ljung-Box
# No se rechaza la hipótsis nula de no autocorrelación de los residuos
Box.test(residuos2,
         lag = 20,
         type = "Ljung-Box",
         fitdf = 2) # p + q cuando testeamos la autocorrelación de residuos de un modelo ARMA(1,10) con 0 para todos los coeficientes de medias móviles menos el de orden 10

```

## Normalidad de los residuos

### QQ-plot de los residuos

```{r, fig.align = 'center', fig.cap = "QQ-plot de los residuos de un modelo ARMA(1,10) para la cantidad de visones atrapados.", fig.pos = 'H'}

# Armamos el QQ-plot de los residuos
ggplot(residuos2, aes(sample = residuos2)) + 
  stat_qq() + 
  stat_qq_line(color = "red") +
  labs(x = "Cuantiles teóricos",
       y = "Cuantiles de la muestra")

```

### Histograma de los residuos

```{r, fig.align = 'center', fig.cap = "Histograma de los residuos de un modelo ARMA(1,10) para la cantidad de visones atrapados. La línea roja corresponde a una densidad normal con media y desvío muestrales igual al de los residuos.", fig.pos = 'H'}

# Hacemos un histograma de los residuos
ggplot(data = residuos2) +
  geom_histogram(aes(x = residuos2,y = ..density..)) +
  stat_function(fun = dnorm,
                args = list(mean = mean(residuos2),
                            sd = sd(residuos2)),
                col = "red",
                size = 1) +
  labs(x = "Residuos",
       y = "Densidad")

```

### Contrastes de normalidad de los residuos

```{r}

# Tests de Shapiro y Jarque-Bera
# Se rechaza la hipótesis nula de normalidad dado que hay outliers
shapiro.test(residuos2)
JarqueBera.test(residuos2)

```

## Homocedasticidad de los residuos

```{r, fig.align = 'center', fig.cap = "Gráfico y autocorrelograma del cuadrado de los residuos de un modelo ARMA(1,10) para la cantidad de visones atrapados.", fig.pos = 'H'}

residuos2_2 <- residuos2^2

grafico_residuos2 <- autoplot(residuos2_2) +
  labs(x = "Fecha",
       y = expression(epsilon[t] ^ 2)) 

acf_residuos2 <- ggAcf(residuos2_2,type = "correlation") +
  labs(x = "Rezago",
       y = "FAC",
       title = "")

grid.arrange(grafico_residuos2, acf_residuos2)

```

# Predicción

```{r}

# Obtenemos las predicciones hasta 10 pasos
predicciones <- forecast(modelo2)
predicciones

```

```{r, fig.align = 'center', fig.cap = "Predicciones a 10 pasos de la cantidad de visones atrapados para un modelo ARMA(1,10). Se consideraron intervalos de confianza entre el 51\\% y 99\\%.", fig.pos = 'H'}

# Graficamos las predicciones mediante un fan chart
predicciones <- forecast(modelo2, fan = TRUE)
autoplot(predicciones) +
  labs(x = "Fecha",
       y = "Cantidad de visones atrapados",
       title = "")

```

# Validación de las predicciones

## Errores de predicción a un paso dentro de la muestra

```{r}

# Obtenemos los errores de predicción a un paso dentro de la muestra (residuos)
accuracy(modelo2)

```

## Ajuste fuera de la muestra

```{r}

# Definimos una muestra de entrenamiento ("training set") hasta 1900 inclusive
train_mink <- window(mink, end = 1900)

# Dejamos los datos entre 1901 y 1911 como conjunto de entrenamiento ("test set")
test_mink <- window(mink, start = 1901)
n <- length(test_mink)

```

```{r}

# Estimamos los modelos para el training set
modelo_train <- Arima(y = train_mink,
                      order = c(1, 0, 10),
                      fixed = c(NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA),
                      lambda = NULL)

```

```{r}

# Predecimos fuera de la muestra (el horizonte de predicción será igual al largo del test set)
pred_test <- forecast(modelo_train, h = n)

```

```{r, fig.align = 'center', fig.cap = "Predicciones en el conjunto de prueba de la cantidad de visones atrapados para el modelo ARMA(1,10). La línea azul corresponde a las predicciones.", fig.pos = 'H'}

# Graficamos las predicciones obtenidas
autoplot(pred_test) +
  autolayer(mink, color = "black") +
  labs(x = "Fecha",
       y = "Cantidad de visones",
       title = "")

```

```{r}

# Obtenemos los errores de predicción fuera de la muestra
# El segundo argumento de la función accuracy() corresponde al verdadero valor de la serie (conjunto de prueba)
accuracy(pred_test, test_mink)

```
